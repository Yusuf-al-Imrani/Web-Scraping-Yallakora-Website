{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "import lxml\n",
    "import csv\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking day date from user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a date in the format mm/dd/yyyy: 12/30/2022\n",
      "You entered:  12/30/2022\n",
      "After changing it to data:  2022-12-30\n",
      "After converted back to string on the format %m-%d-%Y:  12-30-2022\n"
     ]
    }
   ],
   "source": [
    "# Accept input from user\n",
    "date_string = input(\"Enter a date in the format mm/dd/yyyy: \")\n",
    "print(\"You entered: \", date_string)\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Convert date string to datetime object\n",
    "date_object = datetime.strptime(date_string, '%m/%d/%Y').date()\n",
    "print(\"After changing it to data: \", date_object)\n",
    "\n",
    "# Convert datetime object back to string with new format\n",
    "new_date_string = datetime.strftime(date_object, '%m-%d-%Y')\n",
    "print(\"After converted back to string on the format %m-%d-%Y: \", new_date_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requesting the webpage and adding the date to it\n",
    "page = requests.get(f\"https://www.yallakora.com/match-center?date={date_string}\")\n",
    "website_URL = \"https://www.yallakora.com\"\n",
    "\n",
    "# Checking the response of the getting the page, if respose is 200; this means we got it fine\n",
    "page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building function that extract match details through segment of the webpage and store it in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_info(championships):\n",
    "        # Looping through the championships\n",
    "        #for championship in championships:\n",
    "        \n",
    "        match_details = []\n",
    "        \n",
    "        #championship_title = championships[1].find(\"h2\").text.strip()\n",
    "        championship_title = championships[1].find(\"a\",{\"class\":\"tourTitle\"}).find_next(\"h2\").text.strip()\n",
    "        team_a = championships[1].find(\"div\",{\"class\":\"allData\"}\n",
    "                                  ).find_next(\"div\", {\"class\":\"teamsData\"}\n",
    "                                             ).find_next(\"div\", {\"class\":\"teams teamA\"}\n",
    "                                                        ).find_next(\"p\").text\n",
    "        team_b = championships[1].find(\"div\",{\"class\":\"allData\"}\n",
    "                                  ).find_next(\"div\", {\"class\":\"teamsData\"}\n",
    "                                             ).find_next(\"div\", {\"class\":\"teams teamB\"}\n",
    "                                                        ).find_next(\"p\").text\n",
    "        time = championships[1].find(\"div\",{\"class\":\"allData\"}\n",
    "                                  ).find_next(\"div\", {\"class\":\"teamsData\"}\n",
    "                                             ).find_next(\"div\", {\"class\":\"MResult\"}\n",
    "                                                        ).find_next(\"span\"\n",
    "                                                                   ).find_next(\"span\"\n",
    "                                                                              ).find_next(\"span\"\n",
    "                                                                                         ).find_next(\"span\").text\n",
    "        team_a_score = championships[1].find(\"div\",{\"class\":\"allData\"}\n",
    "                                  ).find_next(\"div\", {\"class\":\"teamsData\"}\n",
    "                                             ).find_next(\"div\", {\"class\":\"MResult\"}\n",
    "                                                        ).find_next(\"span\").text\n",
    "        \n",
    "        team_b_score = championships[1].find(\"div\",{\"class\":\"allData\"}\n",
    "                                  ).find_next(\"div\", {\"class\":\"teamsData\"}\n",
    "                                             ).find_next(\"div\", {\"class\":\"MResult\"}\n",
    "                                                        ).find_next(\"span\"\n",
    "                                                                   ).find_next(\"span\"\n",
    "                                                                              ).find_next(\"span\").text\n",
    "        \n",
    "        match_status = championships[1].find(\"div\",{\"class\":\"matchStatus\"}).find_next('span').text\n",
    "        \n",
    "        \n",
    "        chanel_streaming = championships[1].find(\"div\",{\"class\":\"channel icon-channel\"}).text\n",
    "        \n",
    "        match_detail_link = website_URL + championships[1].find(\"div\",{\"class\":\"leftCol\"}\n",
    "                                                               ).find_next('a')['href']\n",
    "        \n",
    "        match_week_number = championships[1].find(\"div\",{\"class\":\"date\"}).text\n",
    "\n",
    "        \n",
    "        # Storing the values in dictionary\n",
    "        match = {'Date':date_object, 'Championship_Title':championship_title, 'Team_A':team_a, 'Team_B':team_b,\n",
    "                 'Time':time, 'Team_A_Score':team_a_score, 'Team_B_Score':team_b_score,\n",
    "                 'Match_Status':match_status, 'Chanel_Streaming':chanel_streaming,\n",
    "                 'Match_Detail_Link':match_detail_link,'Match_Week_Number':match_week_number}\n",
    "        \n",
    "        # Appending the match to match_list\n",
    "        match_details.append(match)\n",
    "        \n",
    "        return(match_details)\n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Storing the data in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to store the data scraped in csv file\n",
    "\n",
    "def store_in_csv(match_details, file_name, path):\n",
    "    #C:\\\\Users\\\\yusuf\\\\Data Science\\\\Projects\\\\Web Scraping\\\\Yallakor.com\"+\"\\\\\n",
    "\n",
    "\n",
    "    # Creating Keys to use in match dictionary\n",
    "    keys = ['Date', 'Championship_Title', 'Team_A', 'Team_B', 'Time', 'Team_A_Score', 'Team_B_Score',\n",
    "            'Match_Status', 'Chanel_Streaming', 'Match_Detail_Link','Match_Week_Number']\n",
    "\n",
    "    # Storing the championships details in csv file\n",
    "    with open(path, 'w', newline=\"\") as match_data:\n",
    "        dict_writer = csv.DictWriter(match_data, fieldnames=keys) \n",
    "        dict_writer.writeheader()\n",
    "\n",
    "        # Looping through championships to store its data\n",
    "        for match in match_details: \n",
    "            dict_writer.writerow(match)\n",
    "\n",
    "        # Checking the file creation is done\n",
    "        print(f\"Match data saved to file{file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calling the main function that scrape the website contect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to do the steps of scraping\n",
    "def scraping(page):\n",
    "    \n",
    "    src = page.content\n",
    "    soup =  BeautifulSoup(src, \"lxml\")\n",
    "    \n",
    "    # List to store matches # Creating list to store match details on it\n",
    "    match_details = []\n",
    "    \n",
    "    championships = soup.find_all(\"div\", {'class':'matchCard'})\n",
    "    \n",
    "    # Test championships \n",
    "    #print(championships)\n",
    "    \n",
    "    \n",
    "    # Calling the function that gets match info    \n",
    "    match_details_scraped = get_match_info(championships)\n",
    "    \n",
    "    \n",
    "    file_name = f\"Match_Data_Scraped_{new_date_string}.csv\"\n",
    "    path = \"C:/Users/yusuf/Data Science/Projects/Web Scraping/Yallakor.com\"+\"/\"+file_name\n",
    "    \n",
    "    \n",
    "    # Calling the function that stores the data scraped in csv file\n",
    "    store_in_csv(match_details_scraped, file_name, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match data saved to fileMatch_Data_Scraped_12-30-2022.csv\n"
     ]
    }
   ],
   "source": [
    "scraping(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
